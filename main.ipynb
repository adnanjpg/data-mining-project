{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# preprocessing\n",
                "- find null values\n",
                "- replace with feature mean\n",
                "- find outliers (especially m2)\n",
                "- enumarate categorical features\n",
                "- drop title col\n",
                "- drop id col\n",
                "- convert all prices to try\n",
                "- drop lat lon\n",
                "- convert date values to be of the same race\n",
                "- drop type (bcz all values are flat)\n",
                "- drop currency\n",
                "- remove outlier prices (25000 TL, 8500000TL)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "FILENAME = \"real_estate_data.csv\"\n",
                "df = pd.read_csv(FILENAME)\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find rows where 'bath' column has null values\n",
                "null_bath_rows = df[df['bath'].isnull()]\n",
                "null_bath_rows.isnull().count()\n",
                "df[df[\"rooms\"] == \"Unknown\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Set rooms property"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert 'm2' column to numeric if it's not already\n",
                "df['m2'] = pd.to_numeric(df['m2'], errors='coerce')\n",
                "\n",
                "for i in df[df[\"rooms\"] == \"Unknown\"].index:\n",
                "    m2 = df.iloc[i][\"m2\"]\n",
                "    mode = df[df['m2'] == m2][\"rooms\"].mode()\n",
                "    if not mode.empty:  # Check if mode is not empty\n",
                "        mode_value = mode.iloc[0]  # Take the first mode value\n",
                "        df.at[i, \"rooms\"] = mode_value"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Set residence property"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['resid'] = (df['resid'] == 'unknown') & (df['price'] > 150000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Replace 'None' with np.nan if it's not already done\n",
                "new_df = df.replace('None', np.NaN)\n",
                "\n",
                "# Remove rows with any null values\n",
                "df_cleaned = new_df.dropna()\n",
                "\n",
                "# Save the cleaned DataFrame to a new CSV file\n",
                "df_cleaned.to_csv('cleaned_data.csv', index=False)\n",
                "\n",
                "# Display the cleaned DataFrame\n",
                "\n",
                "df_cleaned\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "df = pd.read_csv('cleaned_data.csv')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "missing_values_summary = df.isnull().sum()\n",
                "missing_values_summary\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DROP FETURES"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Drop lat - lon - type - title - id - due and Status features from dataframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'lat' in df.columns:\n",
                "    df.drop('lat', axis=1, inplace=True)\n",
                "\n",
                "if 'lon' in df.columns:\n",
                "    df.drop('lon', axis=1, inplace=True)\n",
                "\n",
                "if 'type' in df.columns:\n",
                "    df.drop('type', axis=1, inplace=True)\n",
                "\n",
                "if 'title' in df.columns:\n",
                "    df.drop('title', axis=1, inplace=True)\n",
                "\n",
                "if 'Id' in df.columns:\n",
                "    df.drop('Id', axis=1, inplace=True)\n",
                "\n",
                "if 'due' in df.columns:\n",
                "    df.drop('due', axis=1, inplace=True)\n",
                "\n",
                "if 'Status' in df.columns:\n",
                "    df.drop('Status', axis=1, inplace=True)\n",
                "\n",
                "#drop resid column\n",
                "if 'resid' in df.columns:\n",
                "    df.drop('resid', axis=1, inplace=True)\n",
                "\n",
                "df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Change all currency with turkish lira equivalent and drop currency feature"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "if \"currency\" in df.columns:\n",
                "\n",
                "    df.loc[df['currency'] == 'Euro', 'price'] *= 4\n",
                "    df.loc[df['currency'] == 'US Dollar', 'price'] *= 3.5\n",
                "    df.loc[df['currency'] == 'British Pound', 'price'] *= 4.5\n",
                "\n",
                "    df.drop(\"currency\", axis=1, inplace=True)\n",
                "df[\"price\"]\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Outlier detection using confidence interval"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Q1 = df['price'].quantile(0.25)\n",
                "Q3 = df['price'].quantile(0.75)\n",
                "IQR = Q3 - Q1\n",
                "\n",
                "# Define a condition to identify outliers\n",
                "outlier_condition = (df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR))\n",
                "\n",
                "# sadece turk lirasinda karsilasilan bir durum\n",
                "# Display rows containing outliers\n",
                "outliers = df[outlier_condition]\n",
                "df.drop(outliers.index, inplace=True)\n",
                "df\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Date transformation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df.loc()\n",
                "\n",
                "# for tr, en in turkish_months.values():\n",
                "#     df.loc[df['date'].str.contains(tr), 'price']\n",
                "\n",
                "aylar = {\"Ocak\": \"01\", \"Şubat\": \"02\", \"Mart\": \"03\", \"Nisan\": \"04\", \"Mayıs\": \"05\", \"Haziran\": \"06\",\n",
                "             \"Temmuz\": \"07\", \"Ağustos\": \"08\", \"Eylül\": \"09\", \"Ekim\": \"10\", \"Kasım\": \"11\", \"Aralık\": \"12\"}\n",
                "\n",
                "def transform_date(date):\n",
                "    match date:\n",
                "        case str():\n",
                "            result = '-'.join(date.split()[::-1])\n",
                "            for ay, ay_kodu in aylar.items():\n",
                "                result = result.replace(ay, ay_kodu)\n",
                "            \n",
                "            return result\n",
                "        case _:\n",
                "            return date\n",
                "\n",
                "def transform_date_to_ms(date_str) -> int:\n",
                "    from dateutil import parser\n",
                "\n",
                "    match date_str:\n",
                "        case str():\n",
                "            return parser.parse(date_str, dayfirst=True).timestamp().__floor__()\n",
                "        case _:\n",
                "            return int(date_str)\n",
                "\n",
                "\n",
                "# 'date' sütununu dönüştürün\n",
                "df['date'] = df['date'].apply(transform_date)\n",
                "df['date'] = df['date'].apply(transform_date_to_ms)\n",
                "df['date']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bath transformation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def transform_bath(bath):\n",
                "    match bath:\n",
                "        case str():\n",
                "            if \"+\" in bath:\n",
                "                return float(bath.replace(\"+\", \"\"))\n",
                "            else:\n",
                "                return float(bath)\n",
                "        case _:\n",
                "            return bath\n",
                "\n",
                "df[\"bath\"] = df[\"bath\"].apply(transform_bath)\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df[\"rooms\"].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df[\"rooms\"].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Enumeration Process"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pandas import DataFrame\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "def enumerate_column(column: str, df: DataFrame):\n",
                "    le = LabelEncoder()\n",
                "    df[column] = le.fit_transform(df[column])\n",
                "\n",
                "columns_to_enumerate = [\"loc city\", \"loc county\", \"loc dist\", \"rooms\", \"age\", \"floor\", \"heat\", \"\"]\n",
                "df.dtypes\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Date converted from string to epoch ms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# enumerate_column(\"loc city\", df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
                "\n",
                "# Create a box plot for the 'price' column\n",
                "sns.set(style=\"whitegrid\")\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.boxplot(x='price', data=df, orient='v')\n",
                "plt.title('Box Plot for Price')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "obj = (df.dtypes == 'object')\n",
                "object_cols = list(obj[obj].index)\n",
                "print(\"Categorical variables:\",len(object_cols))\n",
                "\n",
                "int_ = (df.dtypes == 'int')\n",
                "num_cols = list(int_[int_].index)\n",
                "print(\"Integer variables:\",len(num_cols))\n",
                "\n",
                "fl = (df.dtypes == 'float')\n",
                "fl_cols = list(fl[fl].index)\n",
                "print(\"Float variables:\",len(fl_cols))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# Make copy to avoid changing original data\n",
                "\n",
                "# Apply label encoder to each column with categorical data\n",
                "label_encoder = LabelEncoder()\n",
                "for col in object_cols:\n",
                "    df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "sns.heatmap(df.corr(),\n",
                "\t\t\tcmap = 'BrBG',\n",
                "\t\t\tfmt = '.2f',\n",
                "\t\t\tlinewidths = 2,\n",
                "\t\t\tannot = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plt.figure(figsize=(18, 36))\n",
                "# plt.title('Categorical Features: Distribution')\n",
                "# plt.xticks(rotation=90)\n",
                "# index = 1\n",
                "\n",
                "# for col in object_cols:\n",
                "# \ty = df[col].value_counts()\n",
                "# \tplt.subplot(11, 4, index)\n",
                "# \tplt.xticks(rotation=90)\n",
                "# \tsns.barplot(x=list(y.index), y=y)\n",
                "# \tindex += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Separate target from predictors\n",
                "y = df.price\n",
                "X = df.drop('price', axis=1)\n",
                "\n",
                "# Divide data into training and validation subsets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
                "                                                      random_state=42)\n",
                "X_train.describe()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "\n",
                "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
                "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "    model.fit(X_train, y_train)\n",
                "    preds = model.predict(X_valid)\n",
                "    return mean_absolute_error(y_valid, preds)\n",
                "\n",
                "# Get names of columns with missing values\n",
                "cols_with_missing = [col for col in X_train.columns\n",
                "                     if X_train[col].isnull().any()]\n",
                "\n",
                "# Drop columns in training and validation data\n",
                "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
                "reduced_X_valid = X_test.drop(cols_with_missing, axis=1)\n",
                "\n",
                "print(\"MAE (Drop columns with missing values):\")\n",
                "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_test))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Scaling\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "sc = StandardScaler()\n",
                "X_train = sc.fit_transform(X_train)\n",
                "X_test = sc.transform(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn import tree\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
                "from sklearn.model_selection import GridSearchCV"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Number of samples in X_train:\", len(X_train))\n",
                "print(\"Number of samples in y_train:\", len(y_train))\n",
                "print(\"Number of samples in X_test:\", len(X_test))\n",
                "print(\"Number of samples in y_valid:\", len(y_test))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "def RandomForest(X_train,y_train, X_test, y_test):\n",
                "    clf = RandomForestClassifier()\n",
                "    x_scaled=sc.fit_transform(X_train)\n",
                "    clf.fit(x_scaled, y_train)\n",
                "    X_test=sc.fit_transform(X_test)\n",
                "    y_pred = clf.predict(X_test)\n",
                "    #print(\"ConfusionMatrix:\")\n",
                "    #print(confusion_matrix(y_test, y_pred))\n",
                "    print(\"accuracy: \",accuracy_score(y_test, y_pred))\n",
                "    print(\"f1_score: \",f1_score(y_test, y_pred, zero_division=1))\n",
                "    sns.heatmap((confusion_matrix(y_test, y_pred)),annot=True,fmt='.5g',cmap=\"YlGn\").set_title('Test Data'); \n",
                "    #return clf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.metrics import mean_squared_error\n",
                "\n",
                "# Create and train the linear regression model\n",
                "model = LinearRegression()\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions on the test set\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "# Calculate and print the mean squared error\n",
                "mse = mean_squared_error(y_test, y_pred)\n",
                "print(f'Mean Squared Error: {mse}')\n",
                "\n",
                "train_accuracy = model.score(X_train, y_train)  # R-squared or another appropriate metric\n",
                "print(f'Train Accuracy: {train_accuracy}')\n",
                "\n",
                "test_accuracy = model.score(X_test, y_test)  # R-squared or another appropriate metric\n",
                "print(f'Test Accuracy: {test_accuracy}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "this can only mean one thing: *Linear regression is unefficient for this dataset*\n",
                "RandomForest(X_train,y_train, X_test,  y_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# decision tree regression\n",
                "\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.metrics import mean_squared_error\n",
                "\n",
                "# Create and train the decision tree regression model\n",
                "tree = DecisionTreeRegressor()\n",
                "tree.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions on the test set\n",
                "y_pred = tree.predict(X_test)\n",
                "\n",
                "# Calculate and print the mean squared error\n",
                "mse = mean_squared_error(y_test, y_pred)\n",
                "print(f'Mean Squared Error: {mse}')\n",
                "\n",
                "train_accuracy = tree.score(X_train, y_train)  # R-squared or another appropriate metric\n",
                "print(f'Train Accuracy: {train_accuracy}')\n",
                "\n",
                "test_accuracy = tree.score(X_test, y_test)  # R-squared or another appropriate metric\n",
                "print(f'Test Accuracy: {test_accuracy}')\n",
                "# # five element from df\n",
                "# X_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Assuming 'df' is your DataFrame containing the dataset\n",
                "# Replace 'your_target_column' with the actual name of your target column\n",
                "\n",
                "# Extract features (X) and target variable (y)\n",
                "X = df.drop('price', axis=1)  # Features\n",
                "y = df['price']  # Target variable\n",
                "\n",
                "# Split the data into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Standardize the data (optional but often recommended for RandomForest)\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "# Initialize the RandomForestRegressor\n",
                "rf_model = RandomForestRegressor(random_state=42)\n",
                "\n",
                "# Fit the model to the training data\n",
                "rf_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Make predictions on the test set\n",
                "y_pred = rf_model.predict(X_test_scaled)\n",
                "\n",
                "# Evaluate the model\n",
                "mse = mean_squared_error(y_test, y_pred)\n",
                "rmse = mse ** 0.5\n",
                "\n",
                "print(\"Mean Squared Error:\", mse)\n",
                "print(\"Root Mean Squared Error:\", rmse)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# Load your dataset\n",
                "# Assuming your dataset is stored in a DataFrame called 'df'\n",
                "# Make sure to preprocess your data and handle any missing values before proceeding\n",
                "\n",
                "# Convert categorical variables to numerical using Label Encoding\n",
                "label_encoder = LabelEncoder()\n",
                "df['loc city'] = label_encoder.fit_transform(df['loc city'])\n",
                "df['loc county'] = label_encoder.fit_transform(df['loc county'])\n",
                "df['loc dist'] = label_encoder.fit_transform(df['loc dist'])\n",
                "df['heat'] = label_encoder.fit_transform(df['heat'])\n",
                "df['bath'] = label_encoder.fit_transform(df['bath'])\n",
                "df['furn'] = label_encoder.fit_transform(df['furn'])\n",
                "df['status'] = label_encoder.fit_transform(df['status'])\n",
                "df['loan'] = label_encoder.fit_transform(df['loan'])\n",
                "df['saler'] = label_encoder.fit_transform(df['saler'])\n",
                "df['exc'] = label_encoder.fit_transform(df['exc'])\n",
                "\n",
                "# Select features (independent variables) and target variable (dependent variable)\n",
                "X = df.drop(['price'], axis=1)  # Assuming 'price' is the target variable\n",
                "y = df['price']\n",
                "\n",
                "# Split the data into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Initialize the Random Forest Regression model\n",
                "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
                "\n",
                "# Train the model on the training set\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions on the training set\n",
                "y_train_pred = model.predict(X_train)\n",
                "\n",
                "# Make predictions on the validation set\n",
                "\n",
                "# Make predictions on the test set\n",
                "y_test_pred = model.predict(X_test)\n",
                "\n",
                "# Evaluate the model on training set\n",
                "mse_train = mean_squared_error(y_train, y_train_pred)\n",
                "print(f'Training MSE: {mse_train}')\n",
                "\n",
                "# Evaluate the model on validation set\n",
                "# Evaluate the model on test set\n",
                "mse_test = mean_squared_error(y_test, y_test_pred)\n",
                "print(f'Test MSE: {mse_test}')  \n",
                "# Now, you can use the trained model to make predictions on new data\n",
                "# For example, you can use model.predict(new_data) where new_data is a DataFrame with the same columns as X_train\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
                "# Train the model\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions on the training set\n",
                "y_train_pred = model.predict(X_train)\n",
                "\n",
                "# Make predictions on the test set\n",
                "y_test_pred = model.predict(X_test)\n",
                "\n",
                "# Calculate regression metrics for training set\n",
                "mse_train = mean_squared_error(y_train, y_train_pred)\n",
                "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
                "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
                "r2_train = r2_score(y_train, y_train_pred)\n",
                "\n",
                "# Calculate regression metrics for test set\n",
                "mse_test = mean_squared_error(y_test, y_test_pred)\n",
                "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
                "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
                "r2_test = r2_score(y_test, y_test_pred)\n",
                "train_accuracy = model.score(X_train, y_train) \n",
                "# Print the results\n",
                "print(\"Metrics for Training Set:\")\n",
                "print(f\"Mean Squared Error (MSE): {mse_train}\")\n",
                "print(f\"Root Mean Squared Error (RMSE): {rmse_train}\")\n",
                "print(f\"Mean Absolute Error (MAE): {mae_train}\")\n",
                "print(f\"R-squared (R2): {r2_train}\")\n",
                "\n",
                "print(\"\\nMetrics for Test Set:\")\n",
                "print(f\"Mean Squared Error (MSE): {mse_test}\")\n",
                "print(f\"Root Mean Squared Error (RMSE): {rmse_test}\")\n",
                "print(f\"Mean Absolute Error (MAE): {mae_test}\")\n",
                "print(f\"R-squared (R2): {r2_test}\")\n",
                "print(f\"Accuracy: {train_accuracy}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_accuracy = model.score(X_test, y_test) \n",
                "print(f\"Accuracy: {test_accuracy}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scatter plot for Training Set\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.scatter(y_train, y_train_pred, color='blue', label='Actual vs. Predicted (Training Set)')\n",
                "plt.title('Actual vs. Predicted Values - Training Set')\n",
                "plt.xlabel('Actual Values')\n",
                "plt.ylabel('Predicted Values')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Scatter plot for Test Set\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.scatter(y_test, y_test_pred, color='red', label='Actual vs. Predicted (Test Set)')\n",
                "plt.title('Actual vs. Predicted Values - Test Set')\n",
                "plt.xlabel('Actual Values')\n",
                "plt.ylabel('Predicted Values')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
