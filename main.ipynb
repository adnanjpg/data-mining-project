{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "- find null values\n",
    "- replace with feature mean\n",
    "- find outliers (especially m2)\n",
    "- enumarate categorical features\n",
    "- drop title col\n",
    "- drop id col\n",
    "- convert all prices to try\n",
    "- drop lat lon\n",
    "- convert date values to be of the same race\n",
    "- drop type (bcz all values are flat)\n",
    "- drop currency\n",
    "- remove outlier prices (25000 TL, 8500000TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"real_estate_data.csv\"\n",
    "df = pd.read_csv(FILENAME)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where 'bath' column has null values\n",
    "null_bath_rows = df[df['bath'].isnull()]\n",
    "null_bath_rows.isnull().count()\n",
    "df[df[\"rooms\"] == \"Unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set rooms property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'm2' column to numeric if it's not already\n",
    "df['m2'] = pd.to_numeric(df['m2'], errors='coerce')\n",
    "\n",
    "for i in df[df[\"rooms\"] == \"Unknown\"].index:\n",
    "    m2 = df.iloc[i][\"m2\"]\n",
    "    mode = df[df['m2'] == m2][\"rooms\"].mode()\n",
    "    if not mode.empty:  # Check if mode is not empty\n",
    "        mode_value = mode.iloc[0]  # Take the first mode value\n",
    "        df.at[i, \"rooms\"] = mode_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set residence property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resid'] = (df['resid'] == 'unknown') & (df['price'] > 150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'None' with np.nan if it's not already done\n",
    "new_df = df.replace('None', np.NaN)\n",
    "\n",
    "# Remove rows with any null values\n",
    "df_cleaned = new_df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "\n",
    "df_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_summary = df.isnull().sum()\n",
    "missing_values_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROP FETURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop lat - lon - type - title - id - due and Status features from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lat' in df.columns:\n",
    "    df.drop('lat', axis=1, inplace=True)\n",
    "\n",
    "if 'lon' in df.columns:\n",
    "    df.drop('lon', axis=1, inplace=True)\n",
    "\n",
    "if 'type' in df.columns:\n",
    "    df.drop('type', axis=1, inplace=True)\n",
    "\n",
    "if 'title' in df.columns:\n",
    "    df.drop('title', axis=1, inplace=True)\n",
    "\n",
    "if 'Id' in df.columns:\n",
    "    df.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "if 'due' in df.columns:\n",
    "    df.drop('due', axis=1, inplace=True)\n",
    "\n",
    "if 'Status' in df.columns:\n",
    "    df.drop('Status', axis=1, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change all currency with turkish lira equivalent and drop currency feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"currency\" in df.columns:\n",
    "\n",
    "    df.loc[df['currency'] == 'Euro', 'price'] *= 4\n",
    "    df.loc[df['currency'] == 'US Dollar', 'price'] *= 3.5\n",
    "    df.loc[df['currency'] == 'British Pound', 'price'] *= 4.5\n",
    "\n",
    "    df.drop(\"currency\", axis=1, inplace=True)\n",
    "df[\"price\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection using confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define a condition to identify outliers\n",
    "outlier_condition = (df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR))\n",
    "\n",
    "# sadece turk lirasinda karsilasilan bir durum\n",
    "# Display rows containing outliers\n",
    "outliers = df[outlier_condition]\n",
    "df.drop(outliers.index, inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc()\n",
    "\n",
    "# for tr, en in turkish_months.values():\n",
    "#     df.loc[df['date'].str.contains(tr), 'price']\n",
    "\n",
    "aylar = {\"Ocak\": \"01\", \"Şubat\": \"02\", \"Mart\": \"03\", \"Nisan\": \"04\", \"Mayıs\": \"05\", \"Haziran\": \"06\",\n",
    "             \"Temmuz\": \"07\", \"Ağustos\": \"08\", \"Eylül\": \"09\", \"Ekim\": \"10\", \"Kasım\": \"11\", \"Aralık\": \"12\"}\n",
    "\n",
    "def transform_date(date):\n",
    "    match date:\n",
    "        case str():\n",
    "            result = '-'.join(date.split()[::-1])\n",
    "            for ay, ay_kodu in aylar.items():\n",
    "                result = result.replace(ay, ay_kodu)\n",
    "            \n",
    "            return result\n",
    "        case _:\n",
    "            return date\n",
    "\n",
    "def transform_date_to_ms(date_str) -> int:\n",
    "    from dateutil import parser\n",
    "\n",
    "    match date_str:\n",
    "        case str():\n",
    "            return parser.parse(date_str, dayfirst=True).timestamp().__floor__()\n",
    "        case _:\n",
    "            return int(date_str)\n",
    "\n",
    "\n",
    "# 'date' sütununu dönüştürün\n",
    "df['date'] = df['date'].apply(transform_date)\n",
    "df['date'] = df['date'].apply(transform_date_to_ms)\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bath transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_bath(bath):\n",
    "    match bath:\n",
    "        case str():\n",
    "            if \"+\" in bath:\n",
    "                return float(bath.replace(\"+\", \"\"))\n",
    "            else:\n",
    "                return float(bath)\n",
    "        case _:\n",
    "            return bath\n",
    "\n",
    "df[\"bath\"] = df[\"bath\"].apply(transform_bath)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rooms\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumeration Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def enumerate_column(column: str, df: DataFrame):\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "\n",
    "columns_to_enumerate = [\"loc city\", \"loc county\", \"loc dist\", \"rooms\", \"age\", \"floor\", \"heat\", \"\"]\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date converted from string to epoch ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "\n",
    "# Create a box plot for the 'price' column\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='price', data=df, orient='v')\n",
    "plt.title('Box Plot for Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = (df.dtypes == 'object')\n",
    "object_cols = list(obj[obj].index)\n",
    "print(\"Categorical variables:\",len(object_cols))\n",
    "\n",
    "int_ = (df.dtypes == 'int')\n",
    "num_cols = list(int_[int_].index)\n",
    "print(\"Integer variables:\",len(num_cols))\n",
    "\n",
    "fl = (df.dtypes == 'float')\n",
    "fl_cols = list(fl[fl].index)\n",
    "print(\"Float variables:\",len(fl_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Make copy to avoid changing original data\n",
    "\n",
    "# Apply label encoder to each column with categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.corr(),\n",
    "\t\t\tcmap = 'BrBG',\n",
    "\t\t\tfmt = '.2f',\n",
    "\t\t\tlinewidths = 2,\n",
    "\t\t\tannot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18, 36))\n",
    "# plt.title('Categorical Features: Distribution')\n",
    "# plt.xticks(rotation=90)\n",
    "# index = 1\n",
    "\n",
    "# for col in object_cols:\n",
    "# \ty = df[col].value_counts()\n",
    "# \tplt.subplot(11, 4, index)\n",
    "# \tplt.xticks(rotation=90)\n",
    "# \tsns.barplot(x=list(y.index), y=y)\n",
    "# \tindex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate target from predictors\n",
    "y = df.price\n",
    "X = df.drop('price', axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"MAE (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate and print the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "train_accuracy = model.score(X_train, y_train)  # R-squared or another appropriate metric\n",
    "print(f'Train Accuracy: {train_accuracy}')\n",
    "\n",
    "test_accuracy = model.score(X_test, y_test)  # R-squared or another appropriate metric\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this can only mean one thing: *Linear regression is unefficient for this dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree regression\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create and train the decision tree regression model\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Calculate and print the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "train_accuracy = tree.score(X_train, y_train)  # R-squared or another appropriate metric\n",
    "print(f'Train Accuracy: {train_accuracy}')\n",
    "\n",
    "test_accuracy = tree.score(X_test, y_test)  # R-squared or another appropriate metric\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
